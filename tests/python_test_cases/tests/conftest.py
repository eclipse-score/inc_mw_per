# *******************************************************************************
# Copyright (c) 2025 Contributors to the Eclipse Foundation
#
# See the NOTICE file(s) distributed with this work for additional
# information regarding copyright ownership.
#
# This program and the accompanying materials are made available under the
# terms of the Apache License Version 2.0 which is available at
# https://www.apache.org/licenses/LICENSE-2.0
#
# SPDX-License-Identifier: Apache-2.0
# *******************************************************************************
import json
import os
from pathlib import Path

import pytest
from testing_utils import BazelTools

FAILED_CONFIGS = []


# Cmdline options
def pytest_addoption(parser):
    parser.addoption(
        "--traces",
        choices=["none", "target", "all"],
        default="none",
        help="Verbosity of traces in output and HTML report. "
        '"none" - show no traces, '
        '"target" - show traces generated by test code, '
        '"all" - show all traces. ',
    )
    parser.addoption(
        "--cpp-target-name",
        type=str,
        default="//tests/cpp_test_scenarios:cpp_test_scenarios",
        help="C++ test scenario executable target.",
    )
    parser.addoption(
        "--rust-target-name",
        type=str,
        default="//tests/rust_test_scenarios:rust_test_scenarios",
        help="Rust test scenario executable target.",
    )
    parser.addoption(
        "--cpp-target-path",
        type=Path,
        help="C++ test scenario executable target.",
    )
    parser.addoption(
        "--rust-target-path",
        type=Path,
        help="Rust test scenario executable target.",
    )
    parser.addoption(
        "--build-scenarios",
        action="store_true",
        help="Build test scenarios executables.",
    )
    parser.addoption(
        "--build-scenarios-timeout",
        type=float,
        default=180.0,
        help="Build command timeout in seconds. Default: %(default)s",
    )
    parser.addoption(
        "--default-execution-timeout",
        type=float,
        default=5.0,
        help="Default execution timeout in seconds. Default: %(default)s",
    )


# Hooks
@pytest.hookimpl(tryfirst=True)
def pytest_sessionstart(session):
    try:
        # Build scenarios.
        if session.config.getoption("--build-scenarios"):
            build_timeout = session.config.getoption("--build-scenarios-timeout")

            # Build Rust test scenarios.
            print("Building Rust test scenarios executable...")
            cargo_tools = BazelTools(option_prefix="rust", build_timeout=build_timeout)
            rust_target_name = session.config.getoption("--rust-target-name")
            cargo_tools.build(rust_target_name)

            # Build C++ test scenarios.
            print("Building C++ test scenarios executable...")
            bazel_tools = BazelTools(option_prefix="cpp", build_timeout=build_timeout)
            cpp_target_name = session.config.getoption("--cpp-target-name")
            bazel_tools.build(cpp_target_name)

    except Exception as e:
        pytest.exit(str(e), returncode=1)


def pytest_html_report_title(report):
    # Change report title
    report.title = "Component Integration Tests Report"


def pytest_html_results_table_header(cells):
    # Create additional table headers
    cells.insert(1, "<th>Test Input</th>")
    cells.insert(2, "<th>Description</th>")
    cells.insert(3, "<th>Test Scenario Name</th>")
    cells.insert(4, "<th>Test Scenario Command</th>")


def pytest_html_results_table_row(report, cells):
    # Create additional table columns with TC __doc__ and execution date
    cells.insert(
        1,
        f'<td><pre style="white-space:pre-wrap;word-wrap:break-word">{json.dumps(report.input)}</pre></td>',
    )
    cells.insert(2, f"<td><pre>{report.description}</pre></td>")
    cells.insert(3, f"<td><pre>{report.scenario}</pre></td>")
    cells.insert(4, f"<td><pre>{report.command}</pre></td>")


@pytest.hookimpl(hookwrapper=True)
def pytest_runtest_makereport(item, call):
    # Extract TC's data
    outcome = yield
    report = outcome.get_result()
    report.description = str(item.function.__doc__)
    report.scenario = item.funcargs.get("scenario_name", "")
    report.input = item.funcargs.get("test_config", "")

    command = []
    for token in item.funcargs.get("command", ""):
        if " " in token:
            command.append(f"'{token}'")
        else:
            command.append(token)
    report.command = " ".join(command)
    # If bazel is used, modify command
    if "BAZEL_VERSION" in os.environ:
        report.command = report.command.replace(
            "tests/",
            "bazel run //tests/",
        ).replace(
            " --name",
            "-- --name",
        )

    # Store failed command for printing in summary
    if report.failed:
        FAILED_CONFIGS.append(
            {
                "nodeid": report.nodeid,
                "command": report.command,
            }
        )


def pytest_terminal_summary(terminalreporter):
    if not FAILED_CONFIGS:
        return
    # Print failed scenarios info
    terminalreporter.write_sep("=", "Failed tests reproduction info")
    terminalreporter.write_line(
        "Run failed scenarios from the repo root working directory\n"
    )

    for entry in FAILED_CONFIGS:
        terminalreporter.write_line(
            f"{entry['nodeid']} | Run command:\n{entry['command']}\n"
        )


def pytest_collection_modifyitems(items: list[pytest.Function]):
    for item in items:
        # Automatically mark tests parametrized with 'version' as 'cpp' or 'rust'
        if hasattr(item, "callspec") and "version" in getattr(
            item.callspec, "params", {}
        ):
            version = item.callspec.params["version"]
            if version == "cpp":
                item.add_marker(pytest.mark.cpp)
            elif version == "rust":
                item.add_marker(pytest.mark.rust)

        # Add custom markers info to XML report
        for marker in item.iter_markers():
            markers_to_process = (
                "PartiallyVerifies",
                "FullyVerifies",
                "Description",
                "TestType",
                "DerivationTechnique",
            )

            if marker.name not in markers_to_process:
                continue

            item.user_properties.append((marker.name, marker.args[0]))
